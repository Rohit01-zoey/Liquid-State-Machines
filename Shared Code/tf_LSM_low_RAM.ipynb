{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"oHIwq83DXiHF","executionInfo":{"status":"ok","timestamp":1663829782307,"user_tz":-330,"elapsed":3017,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}}},"outputs":[],"source":["import numpy as np\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import pickle\n","import tensorflow as tf\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"wV0ydSFuqGNL"},"source":["Load Data"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"42sXyiIeXuFu","executionInfo":{"status":"ok","timestamp":1663829832888,"user_tz":-330,"elapsed":50585,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}}},"outputs":[],"source":["seed = 0\n","rng = np.random.RandomState(seed)\n","np.seterr(all='raise')\n","\n","dataset = 'mnist_784'   # full size 70000\n","data_size = 50000  # Training + validation data size\n","data_size_test = 10000  # Test data size\n","\n","#dataset = 'Fashion-MNIST'   # full size 70000\n","#data_size = 60000  # Training + validation data size\n","#data_size_test = 10000  # Test data size\n","\n","#dataset = 'EMNIST_Balanced' # full size 131600\n","#data_size = 120000  # Training + validation data size\n","#data_size_test = 10000  # Test data size\n","\n","data = fetch_openml(dataset)\n","X_full = data.data\n","y_full = np.float32(data.target)\n","\n","num_images = X_full.shape[0]\n","in_size = X_full.shape[1]\n","\n","if dataset == 'EMNIST_Balanced':\n","  num_output = 47\n","else:\n","  num_output = 10\n","\n","rand_perm = rng.permutation(num_images)\n","    \n","X_full = (X_full - X_full.min()) / ((X_full.max()+0.00001) - X_full.min())\n","X_full = X_full.to_numpy()\n","    \n","X_full = X_full[rand_perm]\n","y_full = y_full[rand_perm]\n","\n","X_train = X_full[:data_size]\n","y_train_data = y_full[:data_size]\n","\n","X_test = X_full[-data_size_test:]\n","y_test_data = y_full[-data_size_test:]"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"x78NZaGeaGrM","executionInfo":{"status":"ok","timestamp":1663829832889,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}}},"outputs":[],"source":["y_train = np.zeros((data_size, num_output))\n","for i in range(y_train.shape[0]):\n","  y_train[i,np.int32(y_train_data[i])] = 1;\n","\n","y_test = np.zeros((data_size_test, num_output))\n","for i in range(y_test_data.shape[0]):\n","  y_test[i,np.int32(y_test_data[i])] = 1;"]},{"cell_type":"markdown","source":["Fill spike dataset"],"metadata":{"id":"WoamwqmUQlDT"}},{"cell_type":"code","source":["num_iter = 250\n","max_in_spikes = 200\n","batch_size = 200\n","\n","'''\n","num_iter = 250\n","max_in_spikes = 200\n","batch_size = 200\n","\n","X_in_train = np.zeros((X_train.shape[0], num_iter, X_train.shape[1]), dtype=np.int8)\n","X_in_test = np.zeros((X_test.shape[0], num_iter, X_test.shape[1]), dtype=np.int8)\n","\n","num_batches = data_size//batch_size\n","num_batches_test = data_size_test//batch_size\n","for b in range(num_batches):\n","  if(b%50==0):\n","    print(\"completed: \", b/num_batches)\n","  batch_data = X_train[b*batch_size:(b+1)*batch_size]*(max_in_spikes/num_iter)\n","  batch_reshp = np.reshape(batch_data, (batch_size, -1, 1))\n","  batch_data_tiled = np.tile(batch_reshp, (1, 1, num_iter))\n","  batch_data_trans = np.transpose(batch_data_tiled, (0,2,1))\n","  batch_in = np.random.uniform(size=(batch_size , num_iter, in_size))\n","  batch_in[batch_in<batch_data_trans] = 1\n","  batch_in[batch_in<1] = 0\n","  X_in_train[b*batch_size:(b+1)*batch_size, :, :] = batch_in\n","\n","for b in range(num_batches_test):\n","  batch_data = X_test[b*batch_size:(b+1)*batch_size]*(max_in_spikes/num_iter)\n","  batch_reshp = np.reshape(batch_data, (batch_size, -1, 1))\n","  batch_data_tiled = np.tile(batch_reshp, (1, 1, num_iter))\n","  batch_data_trans = np.transpose(batch_data_tiled, (0,2,1))\n","  batch_in = np.random.uniform(size=(batch_size , num_iter, in_size))\n","  batch_in[batch_in<batch_data_trans] = 1\n","  batch_in[batch_in<1] = 0\n","  X_in_test[b*batch_size:(b+1)*batch_size, :, :] = batch_in\n","'''\n","# can't load dataset in low RAM, need to generate on the fly"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"7bct5PNyQWki","executionInfo":{"status":"ok","timestamp":1663829832889,"user_tz":-330,"elapsed":10,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}},"outputId":"17e1a1a5-6b36-497e-d884-2c08dc1eb60d"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nnum_iter = 250\\nmax_in_spikes = 200\\nbatch_size = 200\\n\\nX_in_train = np.zeros((X_train.shape[0], num_iter, X_train.shape[1]), dtype=np.int8)\\nX_in_test = np.zeros((X_test.shape[0], num_iter, X_test.shape[1]), dtype=np.int8)\\n\\nnum_batches = data_size//batch_size\\nnum_batches_test = data_size_test//batch_size\\nfor b in range(num_batches):\\n  if(b%50==0):\\n    print(\"completed: \", b/num_batches)\\n  batch_data = X_train[b*batch_size:(b+1)*batch_size]*(max_in_spikes/num_iter)\\n  batch_reshp = np.reshape(batch_data, (batch_size, -1, 1))\\n  batch_data_tiled = np.tile(batch_reshp, (1, 1, num_iter))\\n  batch_data_trans = np.transpose(batch_data_tiled, (0,2,1))\\n  batch_in = np.random.uniform(size=(batch_size , num_iter, in_size))\\n  batch_in[batch_in<batch_data_trans] = 1\\n  batch_in[batch_in<1] = 0\\n  X_in_train[b*batch_size:(b+1)*batch_size, :, :] = batch_in\\n\\nfor b in range(num_batches_test):\\n  batch_data = X_test[b*batch_size:(b+1)*batch_size]*(max_in_spikes/num_iter)\\n  batch_reshp = np.reshape(batch_data, (batch_size, -1, 1))\\n  batch_data_tiled = np.tile(batch_reshp, (1, 1, num_iter))\\n  batch_data_trans = np.transpose(batch_data_tiled, (0,2,1))\\n  batch_in = np.random.uniform(size=(batch_size , num_iter, in_size))\\n  batch_in[batch_in<batch_data_trans] = 1\\n  batch_in[batch_in<1] = 0\\n  X_in_test[b*batch_size:(b+1)*batch_size, :, :] = batch_in\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2608,"status":"ok","timestamp":1663829835491,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"},"user_tz":-330},"id":"O0fNjgDFSycv","outputId":"f8880864-1566-44c9-de54-264c47d74167"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[1 2 3 4]\n"," [5 6 7 8]], shape=(2, 4), dtype=int64)\n","tf.Tensor(\n","[[1 1 1 1]\n"," [2 2 2 2]\n"," [3 3 3 3]\n"," [4 4 4 4]], shape=(4, 4), dtype=int64)\n","tf.Tensor(\n","[[5 5 5 5]\n"," [6 6 6 6]\n"," [7 7 7 7]\n"," [8 8 8 8]], shape=(4, 4), dtype=int64)\n"]}],"source":["#tf tiling practice\n","arr = np.array([[1,2,3,4],[5,6,7,8]])\n","a = tf.constant(arr)\n","c = tf.reshape(a, [2,-1,1])\n","d = tf.tile(c, [1,1,4])\n","print(a)\n","print(d[0,:,:])\n","print(d[1,:,:])"]},{"cell_type":"markdown","metadata":{"id":"ZDfRmZD-qJi2"},"source":["Define Weight matrix"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51355,"status":"ok","timestamp":1663829886843,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"},"user_tz":-330},"id":"SGSuqEDuqEU_","outputId":"c63795fc-63df-4173-ef6b-b0c8d2d8426c"},"outputs":[{"output_type":"stream","name":"stdout","text":["average fan out:  11.87962962962963\n"]}],"source":["Nx = 12\n","Ny = 12\n","Nz = 12\n","N = Nx*Ny*Nz\n","LqW = 3\n","in_conn_density = 0.15\n","inh_fr = 0.2\n","lam = 9\n","\n","W_lsm = np.zeros((N,N))\n","W_in = np.zeros((in_size,N))\n","\n","in_conn_range = np.int32(N*in_conn_density)\n","for i in range(in_size):\n","  input_perm_i = np.arange(N)\n","  np.random.shuffle(input_perm_i)\n","  pos_conn = input_perm_i[:in_conn_range]\n","  neg_conn = input_perm_i[-in_conn_range:]\n","  W_in[i,pos_conn] = LqW\n","  W_in[i,neg_conn] = -LqW\n","\n","input_perm = np.arange(N)\n","np.random.shuffle(input_perm) # first 0.2*N indices are inhibitory\n","inh_range = np.int32(inh_fr*N) # indices 0 to inh_range-1 are inhibitory\n","\n","for i in range(N):\n","  posti = input_perm[i] # input_perm[i] is the post-neuron index\n","  zi = posti//(Nx*Ny)\n","  yi = (posti-zi*Nx*Ny)//Nx\n","  xi = (posti-zi*Nx*Ny)%Nx\n","  for j in range(N):\n","    prej = input_perm[j] # input_perm[j] is the pre-neuron index\n","    zj = prej//(Nx*Ny)\n","    yj = (prej-zj*Nx*Ny)//Nx\n","    xj = (prej-zj*Nx*Ny)%Nx\n","    D = ((xi-xj)**2 + (yi-yj)**2 + (zi-zj)**2)\n","    if i<inh_range and j<inh_range: # II connection, C = 0.3\n","      P = 0.3*np.exp(-D/lam)\n","      Pu1 = np.random.uniform()\n","      if Pu1<P:\n","        W_lsm[prej,posti] = -LqW\n","    if i<inh_range and j>=inh_range: # EI connection, C = 0.1\n","      P = 0.1*np.exp(-D/lam)\n","      Pu1 = np.random.uniform()\n","      if Pu1<P:\n","        W_lsm[prej,posti] = LqW\n","    if i>=inh_range and j<inh_range: # IE connection, C = 0.05\n","      P = 0.05*np.exp(-D/lam)\n","      Pu1 = np.random.uniform()\n","      if Pu1<P:\n","        W_lsm[prej,posti] = -LqW\n","    if i>=inh_range and j>=inh_range: # EE connection, C = 0.2\n","      P = 0.2*np.exp(-D/lam)\n","      Pu1 = np.random.uniform()\n","      if Pu1<P:\n","        W_lsm[prej,posti] = LqW\n","\n","for i in range(N):\n","  W_lsm[i,i] = 0\n","\n","print(\"average fan out: \", np.mean(np.sum(W_lsm, axis=1)/LqW))"]},{"cell_type":"markdown","metadata":{"id":"NTH4Nx0137aV"},"source":["Define Network"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"vYlyzYHzwdi0","executionInfo":{"status":"ok","timestamp":1663829886843,"user_tz":-330,"elapsed":16,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}}},"outputs":[],"source":["\n","def run_LSM(Vm, SI, Sin, SinI, eta, eta1, a1, a2, in_W, W, sc_W, th, n_iter):\n","  Sliq = []\n","  for i in range(n_iter):\n","    Vm = (1-eta)*Vm + a1*(tf.matmul(SI, sc_W*W) + tf.matmul(SinI, in_W))\n","    Sout = tf.cast(Vm>=th, dtype=tf.float32)\n","    Vm = Vm*tf.cast(Vm<th, dtype=tf.float32)\n","    SinI = (1-eta1)*SinI + a2*Sin[:,i,:]\n","    SI = (1-eta1)*SI + a2*Sout\n","    Sliq.append(Sout)\n","  return tf.stack(Sliq, axis=1)\n","\n","# LSM with STDP in Liquid-Liquid (LL) connections\n","def run_LSM_LL_STDP(Vm, SI, Sin, SinI, spT, eta, eta1, a1, a2, in_W, W, th, n_iter, batch_s, Nin, Nrev, Ap, An, a3=0.1, eta2=0.1):\n","  Sliq = []\n","  for i in range(n_iter):\n","    Vm = (1-eta)*Vm + a1*(tf.matmul(SI, W) + tf.matmul(SinI, in_W))\n","    Sout = tf.cast(Vm>=th, dtype=tf.float32)\n","    Vm = Vm*tf.cast(Vm<th, dtype=tf.float32)\n","    SinI = (1-eta1)*SinI + a2*Sin[:,i,:]\n","    SI = (1-eta1)*SI + a2*Sout\n","    spT = (1-eta2)*spT + a3*Sout\n","\n","    dwp = Ap*tf.matmul(tf.transpose(spT), Sout)/batch_s\n","    dwn = -An*tf.matmul(spT, tf.transpose(Sout))/batch_s\n","    W = W + dwp + dwn\n","    \n","    tau_astro = 10\n","    eta_astro = 1/tau_astro\n","    w_astro = 0.01\n","    An = An*(1-eta_astro) + (w_astro/tau_astro)*(tf.reduce_mean(tf.reduce_sum(Sout, axis=1)) - tf.reduce_mean(tf.reduce_sum(Sin[:,i,:], axis=1))) + Ap/tau_astro\n","\n","    Sliq.append(Sout)\n","  return tf.stack(Sliq, axis=1), W, An\n","\n","# LSM with STDP in Input-Liquid (IL) connections\n","def run_LSM_IL_STDP(Vm, SI, Sin, SinI, spT, spT_in, eta, eta1, a1, a2, in_W, W, th, n_iter, batch_s, Nin, Nrev, Ap, An, a3=0.1, eta2=0.1):\n","  Sliq = []\n","  for i in range(n_iter):\n","    Vm = (1-eta)*Vm + a1*(tf.matmul(SI, W) + tf.matmul(SinI, in_W))\n","    Sout = tf.cast(Vm>=th, dtype=tf.float32)\n","    Vm = Vm*tf.cast(Vm<th, dtype=tf.float32)\n","    SinI = (1-eta1)*SinI + a2*Sin[:,i,:]\n","    SI = (1-eta1)*SI + a2*Sout\n","    spT = (1-eta2)*spT + a3*Sout\n","    spT_in = (1-eta2)*spT_in + a3*Sin[:,i,:]\n","\n","    dwp = Ap*tf.matmul(tf.transpose(spT_in), Sout)/batch_s\n","    dwn = -An*tf.matmul(tf.transpose(Sin[:,i,:]), spT)/batch_s\n","    in_W = in_W + dwp + dwn\n","\n","    tau_astro = 10\n","    eta_astro = 1/tau_astro\n","    w_astro = 0.01\n","    An = An*(1-eta_astro) + (w_astro/tau_astro)*(tf.reduce_mean(tf.reduce_sum(Sout, axis=1)) - tf.reduce_mean(tf.reduce_sum(Sin[:,i,:], axis=1))) + Ap/tau_astro\n","\n","    Sliq.append(Sout)\n","  return tf.stack(Sliq, axis=1), in_W, An\n","\n","# LSM with STDP in all (LL and IL) connections\n","def run_LSM_full_STDP(Vm, SI, Sin, SinI, spT, spT_in, eta, eta1, a1, a2, in_W, W, th, n_iter, batch_s, Nin, Nrev, Ap, An, a3=0.1, eta2=0.1):\n","  Sliq = []\n","  for i in range(n_iter):\n","    Vm = (1-eta)*Vm + a1*(tf.matmul(SI, W) + tf.matmul(SinI, in_W))\n","    Sout = tf.cast(Vm>=th, dtype=tf.float32)\n","    Vm = Vm*tf.cast(Vm<th, dtype=tf.float32)\n","    SinI = (1-eta1)*SinI + a2*Sin[:,i,:]\n","    SI = (1-eta1)*SI + a2*Sout\n","    spT = (1-eta2)*spT + a3*Sout\n","    spT_in = (1-eta2)*spT_in + a3*Sin[:,i,:]\n","\n","    '''\n","    spT_reshape = tf.reshape(spT, [batch_s, -1, 1])\n","    spT_rep = tf.tile(spT_reshape, [1, 1, Nrev]) # this is actually (SIrep)T from derivation\n","    spT_rep_in = tf.tile(spT_reshape, [1, 1, Nin]) # this is required for IL weight tuning\n","\n","    spT_in_reshape = tf.reshape(spT_in, [batch_s, -1, 1])\n","    spT_in_rep = tf.tile(spT_in_reshape, [1, 1, Nrev]) # this is actually (SinIrep)T from derivation\n","\n","    Sout_reshape = tf.reshape(Sout, [batch_s, -1, 1])\n","    Sout_rep = tf.tile(Sout_reshape, [1, 1, Nrev]) # this is actually (Srep)T from derivation\n","    Sout_rep_in = tf.tile(Sout_reshape, [1, 1, Nin]) # this is required for IL weight tuning\n","\n","    Sin_reshape = tf.reshape(Sin[:,i,:], [batch_s, -1, 1])\n","    Sin_rep = tf.tile(Sin_reshape, [1, 1, Nrev]) # this is actually (Sinrep)T from derivation\n","\n","    dwp = Ap*tf.reduce_mean(spT_in_rep*tf.transpose(Sout_rep_in,[0,2,1]), axis=0)\n","    dwn = -An*tf.reduce_mean(tf.transpose(spT_rep_in,[0,2,1])*Sin_rep, axis=0)\n","    in_W = in_W + dwp + dwn\n","\n","    dwp = Ap*tf.reduce_mean(spT_rep*tf.transpose(Sout_rep), axis=0)\n","    dwn = -An*tf.reduce_mean(tf.transpose(spT_rep,[0,2,1])*Sout_rep, axis=0)\n","    W = W + dwp + dwn\n","    '''\n","\n","    dwp = Ap*tf.matmul(tf.transpose(spT_in), Sout)/batch_s\n","    dwn = -An*tf.matmul(tf.transpose(Sin[:,i,:]), spT)/batch_s\n","    in_W = in_W + dwp + dwn\n","    \n","    dwp = Ap*tf.matmul(tf.transpose(spT), Sout)/batch_s\n","    dwn = -An*tf.matmul(tf.transpose(Sout), spT)/batch_s\n","    W = W + dwp + dwn\n","    \n","    tau_astro = 10\n","    eta_astro = 1/tau_astro\n","    w_astro = 0.01\n","    An = An*(1-eta_astro) + (w_astro/tau_astro)*(tf.reduce_mean(tf.reduce_sum(Sout, axis=1)) - tf.reduce_mean(tf.reduce_sum(Sin[:,i,:], axis=1))) + Ap/tau_astro\n","\n","    Sliq.append(Sout)\n","  return tf.stack(Sliq, axis=1), in_W, W, An\n"]},{"cell_type":"markdown","source":["Run LSM with STDP to tune weights - Only updating W_in here"],"metadata":{"id":"sdf2ogcbQdj2"}},{"cell_type":"code","source":["batch_size_STDP = 50\n","num_iter_STDP = 20\n","W_lsm_tf = tf.constant(W_lsm, dtype=tf.float32)\n","\n","eta = 0.1\n","eta1 = 0.1\n","a1 = 0.1\n","a2 = 0.1\n","th = 5\n","\n","num_batches = data_size//batch_size_STDP\n","num_batches_test = data_size_test//batch_size_STDP\n","\n","w_scale = 0.95\n","Ap = 0.15\n","An = 0.15\n","\n","for b in range(num_batches):\n","  W_in_tf = tf.constant(W_in, dtype=tf.float32)\n","  #W_lsm_tf = tf.constant(W_lsm, dtype=tf.float32)\n","  if(b%50==0):\n","    print(\"completed: \", b/num_batches)\n","    print(\"An: \", An)\n","  Vm_tf = tf.constant(np.zeros((batch_size_STDP, N)), dtype=tf.float32)\n","  SI_tf = tf.constant(np.zeros((batch_size_STDP, N)), dtype=tf.float32)\n","  SinI_tf = tf.constant(np.zeros((batch_size_STDP, in_size)), dtype=tf.float32)\n","  spT_tf = tf.constant(np.zeros((batch_size_STDP, N)), dtype=tf.float32)\n","  spT_in_tf = tf.constant(np.zeros((batch_size_STDP, in_size)), dtype=tf.float32)\n","\n","  batch_data = X_train[b*batch_size_STDP:(b+1)*batch_size_STDP]*(max_in_spikes/num_iter_STDP)\n","  batch_reshp = np.reshape(batch_data, (batch_size_STDP, -1, 1))\n","  batch_data_tiled = np.tile(batch_reshp, (1, 1, num_iter_STDP))\n","  batch_data_trans = np.transpose(batch_data_tiled, (0,2,1))\n","  batch_in = np.random.uniform(size=(batch_size_STDP , num_iter_STDP, in_size))\n","  batch_in[batch_in<batch_data_trans] = 1\n","  batch_in[batch_in<1] = 0\n","\n","  batch_in_full = batch_in\n","  batch_in_full_tf = tf.constant(batch_in_full[:,:num_iter_STDP,:], dtype=tf.float32)\n","\n","  S_liq, W_in, W_lsm, An = run_LSM_full_STDP(Vm_tf, SI_tf, batch_in_full_tf, SinI_tf, spT_tf, spT_in_tf, eta, eta1, a1, a2, W_in_tf, W_lsm_tf, th, num_iter_STDP, batch_size_STDP, in_size, N, Ap, An)\n","  #S_liq, W_in, An = run_LSM_IL_STDP(Vm_tf, SI_tf, batch_in_full_tf, SinI_tf, spT_tf, spT_in_tf, eta, eta1, a1, a2, W_in_tf, W_lsm_tf, th, num_iter_STDP, batch_size_STDP, in_size, N, Ap, An)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbKLvkkMRXCS","executionInfo":{"status":"ok","timestamp":1663829991908,"user_tz":-330,"elapsed":105080,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}},"outputId":"e51aee42-74ab-4a54-8d1c-918e0d2f896d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["completed:  0.0\n","An:  0.15\n","completed:  0.05\n","An:  tf.Tensor(0.5594615, shape=(), dtype=float32)\n","completed:  0.1\n","An:  tf.Tensor(0.6881141, shape=(), dtype=float32)\n","completed:  0.15\n","An:  tf.Tensor(0.5264671, shape=(), dtype=float32)\n","completed:  0.2\n","An:  tf.Tensor(0.53462094, shape=(), dtype=float32)\n","completed:  0.25\n","An:  tf.Tensor(0.59812987, shape=(), dtype=float32)\n","completed:  0.3\n","An:  tf.Tensor(0.5895335, shape=(), dtype=float32)\n","completed:  0.35\n","An:  tf.Tensor(0.5442413, shape=(), dtype=float32)\n","completed:  0.4\n","An:  tf.Tensor(0.5689179, shape=(), dtype=float32)\n","completed:  0.45\n","An:  tf.Tensor(0.5320575, shape=(), dtype=float32)\n","completed:  0.5\n","An:  tf.Tensor(0.53252643, shape=(), dtype=float32)\n","completed:  0.55\n","An:  tf.Tensor(0.54225767, shape=(), dtype=float32)\n","completed:  0.6\n","An:  tf.Tensor(0.59749734, shape=(), dtype=float32)\n","completed:  0.65\n","An:  tf.Tensor(0.550735, shape=(), dtype=float32)\n","completed:  0.7\n","An:  tf.Tensor(0.53975606, shape=(), dtype=float32)\n","completed:  0.75\n","An:  tf.Tensor(0.59597933, shape=(), dtype=float32)\n","completed:  0.8\n","An:  tf.Tensor(0.5871, shape=(), dtype=float32)\n","completed:  0.85\n","An:  tf.Tensor(0.55945003, shape=(), dtype=float32)\n","completed:  0.9\n","An:  tf.Tensor(0.5593631, shape=(), dtype=float32)\n","completed:  0.95\n","An:  tf.Tensor(0.57027066, shape=(), dtype=float32)\n"]}]},{"cell_type":"code","source":["print(\"max value in W_in : \", np.max(W_in))\n","print(\"min value in W_in : \", np.min(W_in))\n","\n","print(\"max value in W_lsm : \", np.max(W_lsm))\n","print(\"min value in W_lsm : \", np.min(W_lsm))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P2TRP4uBWvh-","executionInfo":{"status":"ok","timestamp":1663829992877,"user_tz":-330,"elapsed":986,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}},"outputId":"17e55906-4096-4a0c-cc64-608c90407da2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["max value in W_in :  8.191046\n","min value in W_in :  -6.2364354\n","max value in W_lsm :  3.0031111\n","min value in W_lsm :  -3.4702284\n"]}]},{"cell_type":"markdown","source":["Run LSM without STDP to generate liquid activations of train and test sets"],"metadata":{"id":"SxfYl5h7aPm-"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z93ajlxM62mQ","outputId":"b319a03d-ebae-4edf-958b-16453a2bb405","executionInfo":{"status":"ok","timestamp":1663830329005,"user_tz":-330,"elapsed":336135,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["completed:  0.0\n","completed:  0.2\n","completed:  0.4\n","completed:  0.6\n","completed:  0.8\n"]}],"source":["batch_size = 200\n","\n","W_lsm_tf = tf.constant(W_lsm, dtype=tf.float32)\n","W_in_tf = tf.constant(W_in, dtype=tf.float32)\n","\n","eta = 0.1\n","eta1 = 0.1\n","a1 = 0.1\n","a2 = 0.1\n","th = 5\n","\n","num_batches = data_size//batch_size\n","num_batches_test = data_size_test//batch_size\n","\n","LSM_out_train = np.zeros((X_train.shape[0],N))\n","LSM_out_test = np.zeros((X_test.shape[0],N))\n","\n","w_scale = 0.95\n","\n","for b in range(num_batches):\n","  if(b%50==0):\n","    print(\"completed: \", b/num_batches)\n","  Vm_tf = tf.constant(np.zeros((batch_size, N)), dtype=tf.float32)\n","  SI_tf = tf.constant(np.zeros((batch_size, N)), dtype=tf.float32)\n","  SinI_tf = tf.constant(np.zeros((batch_size, in_size)), dtype=tf.float32)\n","  spT_tf = tf.constant(np.zeros((batch_size, N)), dtype=tf.float32)\n","\n","  batch_data = X_train[b*batch_size:(b+1)*batch_size]*(max_in_spikes/num_iter)\n","  batch_reshp = np.reshape(batch_data, (batch_size, -1, 1))\n","  batch_data_tiled = np.tile(batch_reshp, (1, 1, num_iter))\n","  batch_data_trans = np.transpose(batch_data_tiled, (0,2,1))\n","  batch_in = np.random.uniform(size=(batch_size , num_iter, in_size))\n","  batch_in[batch_in<batch_data_trans] = 1\n","  batch_in[batch_in<1] = 0\n","\n","  batch_in_full = batch_in\n","  batch_in_full_tf = tf.constant(batch_in_full, dtype=tf.float32)\n","\n","  S_liq = run_LSM(Vm_tf, SI_tf, batch_in_full_tf, SinI_tf, eta, eta1, a1, a2, W_in_tf, W_lsm_tf, w_scale, th, num_iter)\n","  #S_liq, W_lsm = run_LSM_STDP(Vm_tf, SI_tf, test_in_tf, spT_tf, eta, eta1, a1, a2, W_lsm_tf, th, num_iter, batch_size, N)\n","  \n","  S_liq_c = tf.reduce_mean(S_liq, axis=1)\n","  LSM_out_train[b*batch_size:(b+1)*batch_size] = S_liq_c.numpy()\n","\n","for b in range(num_batches_test):\n","  Vm_tf = tf.constant(np.zeros((batch_size, N)), dtype=tf.float32)\n","  SI_tf = tf.constant(np.zeros((batch_size, N)), dtype=tf.float32)\n","  SinI_tf = tf.constant(np.zeros((batch_size, in_size)), dtype=tf.float32)\n","  spT_tf = tf.constant(np.zeros((batch_size, N)), dtype=tf.float32)\n","\n","  batch_data = X_test[b*batch_size:(b+1)*batch_size]*(max_in_spikes/num_iter)\n","  batch_reshp = np.reshape(batch_data, (batch_size, -1, 1))\n","  batch_data_tiled = np.tile(batch_reshp, (1, 1, num_iter))\n","  batch_data_trans = np.transpose(batch_data_tiled, (0,2,1))\n","  batch_in = np.random.uniform(size=(batch_size , num_iter, in_size))\n","  batch_in[batch_in<batch_data_trans] = 1\n","  batch_in[batch_in<1] = 0\n","\n","  batch_in_full = batch_in\n","  batch_in_full_tf = tf.constant(batch_in_full, dtype=tf.float32)\n","\n","  S_liq = run_LSM(Vm_tf, SI_tf, batch_in_full_tf, SinI_tf, eta, eta1, a1, a2, W_in_tf, W_lsm_tf, w_scale, th, num_iter)\n","  #S_liq, W_lsm = run_LSM_STDP(Vm_tf, SI_tf, test_in_tf, spT_tf, eta, eta1, a1, a2, W_lsm_tf, th, num_iter, batch_size, N)\n","  \n","  S_liq_c = tf.reduce_mean(S_liq, axis=1)\n","  LSM_out_test[b*batch_size:(b+1)*batch_size] = S_liq_c.numpy()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"qALXuelif_94","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663830330359,"user_tz":-330,"elapsed":1358,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}},"outputId":"60a862d3-ebd6-4f3d-91b7-4691402b4899"},"outputs":[{"output_type":"stream","name":"stdout","text":["mean LSM spiking (train) :  0.08791386009910472\n","mean LSM spiking (test) :  0.08813886288187073\n"]}],"source":["print(\"mean LSM spiking (train) : \", np.mean(LSM_out_train))\n","print(\"mean LSM spiking (test) : \", np.mean(LSM_out_test))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EVkpaR-d5C7","outputId":"87b90418-97d2-45b3-922a-2c9631a7bc7e","executionInfo":{"status":"ok","timestamp":1663830475934,"user_tz":-330,"elapsed":145583,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["training linear model on LSM\n","test score = 0.9664\n","training linear model without LSM\n","test score without LSM = 0.919\n"]}],"source":["from sklearn import linear_model\n","\n","print(\"training linear model on LSM\")\n","clf = linear_model.SGDClassifier(max_iter=10000, tol=1e-6)\n","clf.fit(LSM_out_train, y_train_data)\n","\n","score = clf.score(LSM_out_test, y_test_data)\n","print(\"test score = \" + str(score))\n","\n","print(\"training linear model without LSM\")\n","clf2 = linear_model.SGDClassifier(max_iter=10000, tol=1e-6)\n","clf2.fit(X_train, y_train_data)\n","\n","score = clf2.score(X_test, y_test_data)\n","print(\"test score without LSM = \" + str(score))\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+6iyK9viZFYC9+e3O00Gn"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}